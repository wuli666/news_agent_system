"""
æµ‹è¯•å¹¶è¡Œæ‰§è¡Œä¼˜åŒ–
"""
import asyncio
import logging
import time
from datetime import datetime
from src.graph.workflow import create_workflow
from src.graph.types import State

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


async def test_parallel_execution():
    """æµ‹è¯•å¹¶è¡Œæ‰§è¡Œæ€§èƒ½"""
    print("\n" + "=" * 60)
    print("å¹¶è¡Œæ‰§è¡Œæ€§èƒ½æµ‹è¯•")
    print("=" * 60)
    print()

    workflow = create_workflow()

    # æœ€å°åŒ–æµ‹è¯•çŠ¶æ€
    initial_state: State = {
        "task": "æµ‹è¯•å¹¶è¡Œæ‰§è¡Œ",
        "date": datetime.now().strftime("%Y-%m-%d"),
        "iteration": 0,
        "max_iterations": 1,  # åªè¿è¡Œ1è½®
        "news_pool": [],
        "news_pool_cursor": 0,
        "latest_news_batch": [],
        "assigned_news": [],
        "text_batch": [],
        "video_batch": [],
        "text_news": [],
        "video_news": [],
        "text_analysis": None,
        "video_analysis": None,
        "text_relationship_graph": None,
        "text_sentiment": None,
        "text_reflection": None,
        "timeline_analysis": None,
        "trend_analysis": None,
        "timeline_chart_path": None,
        "final_report": None,
        "trending_keywords": None,
        "optimized_query": None,
        "supervisor_questions": [],
        "information_gaps": [],
        "text_team_cycle_count": 0,
        "analysis_gap_pending": None,
        "gap_fill_mode": False,
        "skip_sentiment_relationship": False,
        "daily_papers": [],
        "text_tools": None,
        "video_tools": None,
        "research_tools": None,
        "supervisor_decision": "",
        "supervisor_feedback": "",
        "quality_score": 0.0,
        "last_agent": "",
        "research_notes": [],
        "news_images": {},
        "started_at": None,
        "completed_at": None,
    }

    print("ğŸš€ å¼€å§‹æ‰§è¡Œå·¥ä½œæµ...")
    print("   é¢„æœŸè¡Œä¸º:")
    print("   - Collection Team: text_collector âˆ¥ video_collector (å¹¶è¡Œ)")
    print("   - Analysis Team: research âˆ¥ sentiment âˆ¥ relationship (å¹¶è¡Œ)")
    print()

    try:
        start_time = time.time()

        config = {"recursion_limit": 100}
        final_state = await workflow.ainvoke(initial_state, config=config)

        duration = time.time() - start_time

        print()
        print("=" * 60)
        print("æµ‹è¯•ç»“æœ")
        print("=" * 60)
        print(f"âœ… å·¥ä½œæµæ‰§è¡Œå®Œæˆï¼")
        print(f"   æ€»æ‰§è¡Œæ—¶é—´: {duration:.2f}s")
        print(f"   è¿­ä»£æ¬¡æ•°: {final_state.get('iteration', 0)}")
        print(f"   æ–‡æœ¬æ–°é—»: {len(final_state.get('text_news', []))}")
        print(f"   è§†é¢‘æ–°é—»: {len(final_state.get('video_news', []))}")
        print(f"   ç ”ç©¶ç¬”è®°: {len(final_state.get('research_notes', []))}")
        print(f"   è´¨é‡åˆ†æ•°: {final_state.get('quality_score', 0):.2f}")

        if final_state.get("final_report"):
            print(f"\nğŸ“ ç”Ÿæˆäº†æœ€ç»ˆæŠ¥å‘Š")

        print()
        print("=" * 60)
        print("å¹¶è¡Œæ‰§è¡ŒéªŒè¯")
        print("=" * 60)
        print("âœ… æ£€æŸ¥æ—¥å¿—ä¸­æ˜¯å¦å‡ºç°ä»¥ä¸‹æ ‡è®°:")
        print("   ğŸ”€ Parallel routing: ... (Collection Team)")
        print("   ğŸ”€ Full analysis: research âˆ¥ sentiment âˆ¥ relationship (Analysis Team)")
        print()

        return True

    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}", exc_info=True)
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        return False


if __name__ == "__main__":
    success = asyncio.run(test_parallel_execution())
    print("\n" + "=" * 60)
    if success:
        print("âœ… å¹¶è¡Œæ‰§è¡Œæµ‹è¯•é€šè¿‡ï¼")
        print("   å»ºè®®: æ£€æŸ¥æ—¥å¿—è¾“å‡ºï¼Œç¡®è®¤çœ‹åˆ°å¹¶è¡Œè·¯ç”±æ ‡è®°")
    else:
        print("âŒ å¹¶è¡Œæ‰§è¡Œæµ‹è¯•å¤±è´¥")
        print("   å»ºè®®: æ£€æŸ¥é”™è¯¯æ—¥å¿—")
    print("=" * 60)
